# ğŸ“‹ quark_auto_save.py è¯¦ç»†åˆ†æ

## ğŸ—ï¸ æ–‡ä»¶æ•´ä½“ç»“æ„åˆ†æ

### 1. æ–‡ä»¶å¤´éƒ¨å’Œå¯¼å…¥ (è¡Œ 1-36)

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Modify: 2025-09-05
# Repo: https://github.com/Cp0204/quark_auto_save
# ConfigFile: quark_config.json
"""
new Env('å¤¸å…‹è‡ªåŠ¨è¿½æ›´');
0 8,18,20 * * * quark_auto_save.py
"""
```

**æ–‡ä»¶ä¿¡æ¯**ï¼š
- **é¡¹ç›®åç§°**: å¤¸å…‹è‡ªåŠ¨è¿½æ›´
- **å»ºè®®æ‰§è¡Œæ—¶é—´**: æ¯å¤©8ç‚¹ã€18ç‚¹ã€20ç‚¹
- **é…ç½®æ–‡ä»¶**: `quark_config.json`
- **ä»“åº“åœ°å€**: GitHubå¼€æºé¡¹ç›®

### 2. å¯¼å…¥æ¨¡å—åˆ†æ

```python
# åŸºç¡€åº“
import os, re, sys, json, time, random, requests, importlib, traceback, urllib.parse
from datetime import datetime
from natsort import natsorted

# é¡¹ç›®ç‰¹å®šå¯¼å…¥
from treelib import Tree
```

**ä¾èµ–åˆ†æ**ï¼š
- **æ ‡å‡†åº“**: æ–‡ä»¶æ“ä½œã€ç½‘ç»œè¯·æ±‚ã€æ­£åˆ™è¡¨è¾¾å¼
- **ç¬¬ä¸‰æ–¹åº“**: `natsort`(è‡ªç„¶æ’åº)ã€`treelib`(æ ‘å½¢æ•°æ®ç»“æ„)
- **ç½‘ç»œè¯·æ±‚**: `requests` ç”¨äºHTTPé€šä¿¡
- **åŠ¨æ€å¯¼å…¥**: `importlib` æ”¯æŒæ’ä»¶åŠ è½½

### 3. å…¨å±€å˜é‡å’Œå¸¸é‡ (è¡Œ 32-36)

```python
CONFIG_DATA = {}
NOTIFYS = []
GH_PROXY = os.environ.get("GH_PROXY", "https://ghproxy.net/")
```

**å…¨å±€çŠ¶æ€ç®¡ç†**ï¼š
- `CONFIG_DATA`: å…¨å±€é…ç½®æ•°æ®ç¼“å­˜
- `NOTIFYS`: é€šçŸ¥æ¶ˆæ¯æ”¶é›†åˆ—è¡¨
- `GH_PROXY`: GitHubä»£ç†é…ç½®ï¼Œæ”¯æŒå›½å†…ç½‘ç»œç¯å¢ƒ

## ğŸ”§ æ ¸å¿ƒç±»å’Œå‡½æ•°å®ç°

### 1. é€šçŸ¥ç³»ç»Ÿ (è¡Œ 37-58)

```python
# å‘é€é€šçŸ¥æ¶ˆæ¯
def send_ql_notify(title, body):
    try:
        # å¯¼å…¥é€šçŸ¥æ¨¡å—
        import notify

        # å¦‚æœªé…ç½® push_config åˆ™ä½¿ç”¨é’é¾™ç¯å¢ƒé€šçŸ¥è®¾ç½®
        if CONFIG_DATA.get("push_config"):
            notify.push_config.update(CONFIG_DATA["push_config"])
            notify.push_config["CONSOLE"] = notify.push_config.get("CONSOLE", True)
        notify.send(title, body)
    except Exception as e:
        if e:
            print("å‘é€é€šçŸ¥æ¶ˆæ¯å¤±è´¥ï¼")

# æ·»åŠ æ¶ˆæ¯
def add_notify(text):
    global NOTIFYS
    NOTIFYS.append(text)
    print("ğŸ“¢", text)
    return text
```

**é€šçŸ¥ç³»ç»Ÿç‰¹ç‚¹**ï¼š
- **æ¨¡å—åŒ–è®¾è®¡**: ç‹¬ç«‹çš„é€šçŸ¥æ¨¡å—
- **å¤šæ¸ é“æ”¯æŒ**: æ§åˆ¶å°ã€æ¨é€ç­‰å¤šç§é€šçŸ¥æ–¹å¼
- **é”™è¯¯å®¹é”™**: é€šçŸ¥å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
- **æ¶ˆæ¯æ”¶é›†**: ç»Ÿä¸€æ”¶é›†æ‰€æœ‰é€šçŸ¥æ¶ˆæ¯

### 2. Config å·¥å…·ç±» (è¡Œ 61-138)

#### æ–‡ä»¶æ“ä½œæ–¹æ³• (è¡Œ 62-82)

```python
class Config:
    # ä¸‹è½½é…ç½®
    def download_file(url, save_path):
        response = requests.get(url)
        if response.status_code == 200:
            with open(save_path, "wb") as file:
                file.write(response.content)
            return True
        else:
            return False

    # è¯»å– JSON æ–‡ä»¶å†…å®¹
    def read_json(config_path):
        with open(config_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data

    # å°†æ•°æ®å†™å…¥ JSON æ–‡ä»¶
    def write_json(config_path, data):
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, sort_keys=False, indent=2)
```

**åŠŸèƒ½ç‰¹ç‚¹**ï¼š
- **æ–‡ä»¶ä¸‹è½½**: æ”¯æŒè¿œç¨‹é…ç½®æ¨¡æ¿ä¸‹è½½
- **JSONæ“ä½œ**: ç»Ÿä¸€çš„é…ç½®æ–‡ä»¶è¯»å†™æ¥å£
- **ç¼–ç å¤„ç†**: ç¡®ä¿ä¸­æ–‡å­—ç¬¦æ­£ç¡®å¤„ç†

#### Cookie å¤„ç†å‡½æ•° (è¡Œ 84-93)

```python
def get_cookies(cookie_val):
    if isinstance(cookie_val, list):
        return cookie_val
    elif cookie_val:
        if "\n" in cookie_val:
            return cookie_val.split("\n")
        else:
            return [cookie_val]
    else:
        return False
```

**æ™ºèƒ½Cookieå¤„ç†**ï¼š
- æ”¯æŒå­—ç¬¦ä¸²å’Œåˆ—è¡¨ä¸¤ç§æ ¼å¼
- è‡ªåŠ¨åˆ†å‰²å¤šè´¦å·Cookie
- ç©ºå€¼å®‰å…¨å¤„ç†

#### æ’ä»¶åŠ è½½ç³»ç»Ÿ (è¡Œ 95-131)

```python
def load_plugins(plugins_config={}, plugins_dir="plugins"):
    PLUGIN_FLAGS = os.environ.get("PLUGIN_FLAGS", "").split(",")
    plugins_available = {}
    task_plugins_config = {}
    all_modules = [
        f.replace(".py", "") for f in os.listdir(plugins_dir) if f.endswith(".py")
    ]

    # è°ƒæ•´æ¨¡å—ä¼˜å…ˆçº§
    priority_path = os.path.join(plugins_dir, "_priority.json")
    try:
        with open(priority_path, encoding="utf-8") as f:
            priority_modules = json.load(f)
        if priority_modules:
            all_modules = [
                module for module in priority_modules if module in all_modules
            ] + [module for module in all_modules if module not in priority_modules]
    except (FileNotFoundError, json.JSONDecodeError):
        priority_modules = []

    for module_name in all_modules:
        if f"-{module_name}" in PLUGIN_FLAGS:
            continue  # è·³è¿‡ç¦ç”¨çš„æ’ä»¶
        try:
            module = importlib.import_module(f"{plugins_dir}.{module_name}")
            ServerClass = getattr(module, module_name.capitalize())
            # æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å­˜åœ¨è¯¥æ¨¡å—çš„é…ç½®
            if module_name in plugins_config:
                plugin = ServerClass(**plugins_config[module_name])
                plugins_available[module_name] = plugin
            else:
                plugin = ServerClass()
                plugins_config[module_name] = plugin.default_config
            # æ£€æŸ¥æ’ä»¶æ˜¯å¦æ”¯æŒå•ç‹¬ä»»åŠ¡é…ç½®
            if hasattr(plugin, "default_task_config"):
                task_plugins_config[module_name] = plugin.default_task_config
        except (ImportError, AttributeError) as e:
            print(f"è½½å…¥æ¨¡å— {module_name} å¤±è´¥: {e}")
    return plugins_available, plugins_config, task_plugins_config
```

**æ’ä»¶ç³»ç»Ÿç‰¹æ€§**ï¼š
- **åŠ¨æ€åŠ è½½**: è¿è¡Œæ—¶åŠ¨æ€å¯¼å…¥æ’ä»¶æ¨¡å—
- **ä¼˜å…ˆçº§æ§åˆ¶**: æ”¯æŒ `_priority.json` é…ç½®åŠ è½½é¡ºåº
- **ç¯å¢ƒå˜é‡æ§åˆ¶**: `PLUGIN_FLAGS` å¯ç¦ç”¨ç‰¹å®šæ’ä»¶
- **é…ç½®æ³¨å…¥**: è‡ªåŠ¨æ³¨å…¥æ’ä»¶é…ç½®å‚æ•°
- **ä»»åŠ¡é…ç½®**: æ”¯æŒæ’ä»¶çº§åˆ«çš„ä»»åŠ¡é…ç½®

#### ç‰ˆæœ¬å…¼å®¹æ€§å¤„ç† (è¡Œ 133-138)

```python
def breaking_change_update(config_data):
    # ğŸ”¼ Update config v0.5.x to 0.6.0
    for task in config_data.get("tasklist", []):
        if "$TASKNAME" in task.get("replace", ""):
            task["replace"] = task["replace"].replace("$TASKNAME", "{TASKNAME}")
```

**å…¼å®¹æ€§ä¿è¯**ï¼š
- è‡ªåŠ¨å¤„ç†é…ç½®æ ¼å¼å˜æ›´
- å‘åå…¼å®¹æ—§ç‰ˆæœ¬é…ç½®
- å¹³æ»‘å‡çº§æœºåˆ¶

## ğŸª„ MagicRename é­”æ³•é‡å‘½åç³»ç»Ÿ

### 1. é­”æ³•æ­£åˆ™é…ç½® (è¡Œ 140-181)

```python
class MagicRename:
    magic_regex = {
        "$TV": {
            "pattern": r".*?([Ss]\d{1,2})?(?:[ç¬¬EePpXx\.\-\_\( ]{1,2}|^)(\d{1,3})(?!\d).*?\.(mp4|mkv)",
            "replace": r"\1E\2.\3",
        },
        "$BLACK_WORD": {
            "pattern": r"^(?!.*çº¯äº«)(?!.*åŠ æ›´)(?!.*è¶…å‰ä¼åˆ’)(?!.*è®­ç»ƒå®¤)(?!.*è’¸è’¸æ—¥ä¸Š).*",
            "replace": "",
        },
    }

    magic_variable = {
        "{TASKNAME}": "",
        "{I}": 1,
        "{EXT}": [r"(?<=\.)\w+$"],
        "{CHINESE}": [r"[\u4e00-\u9fa5]{2,}"],
        "{DATE}": [
            r"(18|19|20)?\d{2}[\.\-/å¹´]\d{1,2}[\.\-/æœˆ]\d{1,2}",
            r"(?<!\d)[12]\d{3}[01]?\d[0123]?\d",
            r"(?<!\d)[01]?\d[\.\-/æœˆ][0123]?\d",
        ],
        "{YEAR}": [r"(?<!\d)(18|19|20)\d{2}(?!\d)"],
        "{S}": [r"(?<=[Ss])\d{1,2}(?=[EeXx])", r"(?<=[Ss])\d{1,2}"],
        "{SXX}": [r"[Ss]\d{1,2}(?=[EeXx])", r"[Ss]\d{1,2}"],
        "{E}": [
            r"(?<=[Ss]\d\d[Ee])\d{1,3}",
            r"(?<=[Ee])\d{1,3}",
            r"(?<=[Ee][Pp])\d{1,3}",
            r"(?<=ç¬¬)\d{1,3}(?=[é›†æœŸè¯éƒ¨ç¯‡])",
            r"(?<!\d)\d{1,3}(?=[é›†æœŸè¯éƒ¨ç¯‡])",
            r"(?!.*19)(?!.*20)(?<=[\._])\d{1,3}(?=[\._])",
            r"^\d{1,3}(?=\.\w+)",
            r"(?<!\d)\d{1,3}(?!\d)(?!$)",
        ],
        "{PART}": [
            r"(?<=[é›†æœŸè¯éƒ¨ç¯‡ç¬¬])[ä¸Šä¸­ä¸‹ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]",
            r"[ä¸Šä¸­ä¸‹ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]",
        ],
        "{VER}": [r"[\u4e00-\u9fa5]+ç‰ˆ"],
    }
```

**é­”æ³•ç³»ç»Ÿç‰¹ç‚¹**ï¼š
- **é¢„å®šä¹‰æ­£åˆ™**: å¸¸ç”¨å‘½åè§„åˆ™æ¨¡æ¿
- **å¤šæ¨¡å¼åŒ¹é…**: æ”¯æŒå¤šç§æ ¼å¼è¯†åˆ«
- **å˜é‡ç³»ç»Ÿ**: æ™ºèƒ½å†…å®¹æå–å’Œæ›¿æ¢
- **ä¸­æ–‡æ”¯æŒ**: å®Œæ•´çš„ä¸­æ–‡å­—ç¬¦å¤„ç†

### 2. æ’åºä¼˜å…ˆçº§ (è¡Œ 183-200)

```python
priority_list = [
    "ä¸Š", "ä¸­", "ä¸‹",
    "ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å",
    "ç™¾", "åƒ", "ä¸‡"
]
```

**æ’åºé€»è¾‘**ï¼š
- ä¸­æ–‡æ•°å­—è‡ªç„¶æ’åº
- æ”¯æŒå‰§é›†éƒ¨åˆ†æ ‡è¯†
- ç¡®ä¿æ–‡ä»¶å‘½åä¸€è‡´æ€§

### 3. æ ¸å¿ƒé‡å‘½åå‡½æ•°

#### åˆå§‹åŒ–æ–¹æ³• (è¡Œ 202-210)

```python
def __init__(self, magic_regex={}, magic_variable={}):
    self.magic_regex.update(magic_regex)
    self.magic_variable.update(magic_variable)
    self.dir_filename_dict = {}

def set_taskname(self, taskname):
    """è®¾ç½®ä»»åŠ¡åç§°"""
    self.magic_variable["{TASKNAME}"] = taskname
```

#### é­”æ³•æ­£åˆ™è½¬æ¢ (è¡Œ 211-218)

```python
def magic_regex_conv(self, pattern, replace):
    """é­”æ³•æ­£åˆ™åŒ¹é…"""
    keyword = pattern
    if keyword in self.magic_regex:
        pattern = self.magic_regex[keyword]["pattern"]
        if replace == "":
            replace = self.magic_regex[keyword]["replace"]
    return pattern, replace
```

#### å˜é‡æ›¿æ¢å¤„ç† (è¡Œ 220-258)

```python
def sub(self, pattern, replace, file_name):
    """é­”æ³•æ­£åˆ™ã€å˜é‡æ›¿æ¢"""
    if not replace:
        return file_name

    # é¢„å¤„ç†æ›¿æ¢å˜é‡
    for key, p_list in self.magic_variable.items():
        if key in replace:
            # æ­£åˆ™ç±»æ›¿æ¢å˜é‡
            if p_list and isinstance(p_list, list):
                for p in p_list:
                    match = re.search(p, file_name)
                    if match:
                        value = match.group()
                        # æ—¥æœŸæ ¼å¼å¤„ç†ï¼šè¡¥å…¨ã€æ ¼å¼åŒ–
                        if key == "{DATE}":
                            value = "".join([char for char in value if char.isdigit()])
                            value = str(datetime.now().year)[: (8 - len(value))] + value
                        replace = replace.replace(key, value)
                        break
            # éæ­£åˆ™ç±»æ›¿æ¢å˜é‡
            if key == "{TASKNAME}":
                replace = replace.replace(key, self.magic_variable["{TASKNAME}"])
            elif key == "{SXX}" and not match:
                replace = replace.replace(key, "S01")
            elif key == "{I}":
                continue
            else:
                # æ¸…ç†æœªåŒ¹é…çš„ magic_variable key
                replace = replace.replace(key, "")

    if pattern and replace:
        file_name = re.sub(pattern, replace, file_name)
    else:
        file_name = replace
    return file_name
```

**æ™ºèƒ½å˜é‡å¤„ç†**ï¼š
- **å¤šæ¨¡å¼åŒ¹é…**: æ”¯æŒåŒä¸€å˜é‡çš„å¤šç§è¯†åˆ«æ¨¡å¼
- **æ—¥æœŸæ™ºèƒ½å¤„ç†**: è‡ªåŠ¨è¡¥å…¨å¹´ä»½ï¼Œæ ¼å¼åŒ–æ—¥æœŸ
- **é»˜è®¤å€¼å¤„ç†**: æœªåŒ¹é…æ—¶æä¾›åˆç†é»˜è®¤å€¼
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**: æ ¹æ®ä»»åŠ¡åç§°åŠ¨æ€æ›¿æ¢

#### è‡ªå®šä¹‰æ’åºé”® (è¡Œ 260-265)

```python
def _custom_sort_key(self, name):
    """è‡ªå®šä¹‰æ’åºé”®"""
    for i, keyword in enumerate(self.priority_list):
        if keyword in name:
            name = name.replace(keyword, f"_{i:02d}_")  # æ›¿æ¢ä¸ºæ•°å­—ï¼Œæ–¹ä¾¿æ’åº
    return name
```

#### æ–‡ä»¶åˆ—è¡¨æ’åº (è¡Œ 267-300)

```python
def sort_file_list(self, file_list, dir_filename_dict={}):
    """æ–‡ä»¶åˆ—è¡¨ç»Ÿä¸€æ’åºï¼Œç»™{I+}èµ‹å€¼"""
    filename_list = [
        # å¼ºåˆ¶åŠ å…¥`æ–‡ä»¶ä¿®æ”¹æ—¶é—´`å­—æ®µä¾›æ’åº
        f"{f['file_name_re']}_{f['updated_at']}"
        for f in file_list
        if f.get("file_name_re") and not f["dir"]
    ]

    dir_filename_dict = dir_filename_dict or self.dir_filename_dict
    # åˆå¹¶ç›®å½•æ–‡ä»¶åˆ—è¡¨
    filename_list = list(set(filename_list) | set(dir_filename_dict.values()))
    filename_list = natsorted(filename_list, key=self._custom_sort_key)

    filename_index = {}
    for name in filename_list:
        if name in dir_filename_dict.values():
            continue
        i = filename_list.index(name) + 1
        while i in dir_filename_dict.keys():
            i += 1
        dir_filename_dict[i] = name
        filename_index[name] = i

    for file in file_list:
        if file.get("file_name_re"):
            if match := re.search(r"\{I+\}", file["file_name_re"]):
                i = filename_index.get(
                    f"{file['file_name_re']}_{file['updated_at']}", 0
                )
                file["file_name_re"] = re.sub(
                    match.group(),
                    str(i).zfill(match.group().count("I")),
                    file["file_name_re"],
                )
```

#### ç›®å½•æ–‡ä»¶åˆ—è¡¨è®¾ç½® (è¡Œ 302-329)

```python
def set_dir_file_list(self, file_list, replace):
    """è®¾ç½®ç›®å½•æ–‡ä»¶åˆ—è¡¨"""
    self.dir_filename_dict = {}
    filename_list = [f["file_name"] for f in file_list if not f["dir"]]
    filename_list.sort()

    if not filename_list:
        return

    if match := re.search(r"\{I+\}", replace):
        # ç”±æ›¿æ¢å¼è½¬æ¢åŒ¹é…å¼
        magic_i = match.group()
        pattern_i = r"\d" * magic_i.count("I")
        pattern = replace.replace(match.group(), "ğŸ”¢")
        for key, _ in self.magic_variable.items():
            if key in pattern:
                pattern = pattern.replace(key, "ğŸ”£")
        pattern = re.sub(r"\\[0-9]+", "ğŸ”£", pattern)  # \1 \2 \3
        pattern = f"({re.escape(pattern).replace('ğŸ”£', '.*?').replace('ğŸ”¢', f')({pattern_i})(')})"

        # è·å–èµ·å§‹ç¼–å·
        if match := re.match(pattern, filename_list[-1]):
            self.magic_variable["{I}"] = int(match.group(2))

        # ç›®å½•æ–‡ä»¶åˆ—è¡¨
        for filename in filename_list:
            if match := re.match(pattern, filename):
                self.dir_filename_dict[int(match.group(2))] = (
                    match.group(1) + magic_i + match.group(3)
                )
```

#### æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥ (è¡Œ 331-347)

```python
def is_exists(self, filename, filename_list, ignore_ext=False):
    """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¤„ç†å¿½ç•¥æ‰©å±•å"""
    if ignore_ext:
        filename = os.path.splitext(filename)[0]
        filename_list = [os.path.splitext(f)[0] for f in filename_list]

    # {I+} æ¨¡å¼ï¼Œç”¨Ié€šé…æ•°å­—åºå·
    if match := re.search(r"\{I+\}", filename):
        magic_i = match.group()
        pattern_i = r"\d" * magic_i.count("I")
        pattern = re.escape(filename).replace(re.escape(magic_i), pattern_i)
        for filename in filename_list:
            if re.match(pattern, filename):
                return filename
        return None
    else:
        return filename if filename in filename_list else None
```

## ğŸŒ Quark API å°è£…å’Œè¯·æ±‚æœºåˆ¶

### 1. Quark ç±»åˆå§‹åŒ– (è¡Œ 350-374)

```python
class Quark:
    BASE_URL = "https://drive-pc.quark.cn"
    BASE_URL_APP = "https://drive-m.quark.cn"
    USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) quark-cloud-drive/3.14.2 Chrome/112.0.5615.165 Electron/24.1.3.8 Safari/537.36 Channel/pckk_other_ch"

    def __init__(self, cookie="", index=0):
        self.cookie = cookie.strip()
        self.index = index + 1
        self.is_active = False
        self.nickname = ""
        self.mparam = self._match_mparam_form_cookie(cookie)
        self.savepath_fid = {"/": "0"}
```

**åˆå§‹åŒ–ç‰¹æ€§**ï¼š
- **åŒç«¯æ”¯æŒ**: PCç«¯å’Œç§»åŠ¨ç«¯API
- **çœŸå®UA**: æ¨¡æ‹Ÿå®˜æ–¹å®¢æˆ·ç«¯User-Agent
- **Cookieè§£æ**: æå–ç§»åŠ¨ç«¯å¿…è¦å‚æ•°
- **è·¯å¾„ç¼“å­˜**: ç¼“å­˜ç›®å½•IDæ˜ å°„å…³ç³»

### 2. ç§»åŠ¨ç«¯å‚æ•°æå– (è¡Œ 363-374)

```python
def _match_mparam_form_cookie(self, cookie):
    mparam = {}
    kps_match = re.search(r"(?<!\w)kps=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
    sign_match = re.search(r"(?<!\w)sign=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
    vcode_match = re.search(r"(?<!\w)vcode=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
    if kps_match and sign_match and vcode_match:
        mparam = {
            "kps": kps_match.group(1).replace("%25", "%"),
            "sign": sign_match.group(1).replace("%25", "%"),
            "vcode": vcode_match.group(1).replace("%25", "%"),
        }
    return mparam
```

**å‚æ•°æå–é€»è¾‘**ï¼š
- **æ­£åˆ™åŒ¹é…**: ç²¾ç¡®æå–å…³é”®å‚æ•°
- **URLè§£ç **: å¤„ç†ç¼–ç å­—ç¬¦
- **å®Œæ•´æ€§æ£€æŸ¥**: ç¡®ä¿å¿…è¦å‚æ•°å­˜åœ¨

### 3. æ ¸å¿ƒè¯·æ±‚æ–¹æ³• (è¡Œ 376-426)

```python
def _send_request(self, method, url, **kwargs):
    headers = {
        "cookie": self.cookie,
        "content-type": "application/json",
        "user-agent": self.USER_AGENT,
    }
    if "headers" in kwargs:
        headers = kwargs["headers"]
        del kwargs["headers"]

    # ç§»åŠ¨ç«¯è¯·æ±‚å¤„ç†
    if self.mparam and "share" in url and self.BASE_URL in url:
        url = url.replace(self.BASE_URL, self.BASE_URL_APP)
        kwargs["params"].update({
            "device_model": "M2011K2C",
            "entry": "default_clouddrive",
            "_t_group": "0%3A_s_vp%3A1",
            "dmn": "Mi%2B11",
            "fr": "android",
            "pf": "3300",
            "bi": "35937",
            "ve": "7.4.5.680",
            "ss": "411x875",
            "mi": "M2011K2C",
            "nt": "5",
            "nw": "0",
            "kt": "4",
            "pr": "ucpro",
            "sv": "release",
            "dt": "phone",
            "data_from": "ucapi",
            "kps": self.mparam.get("kps"),
            "sign": self.mparam.get("sign"),
            "vcode": self.mparam.get("vcode"),
            "app": "clouddrive",
            "kkkk": "1",
        })
        del headers["cookie"]

    try:
        response = requests.request(method, url, headers=headers, **kwargs)
        return response
    except Exception as e:
        print(f"_send_request error:\n{e}")
        # åˆ›å»ºå‡å“åº”é¿å…ç¨‹åºå´©æºƒ
        fake_response = requests.Response()
        fake_response.status_code = 500
        fake_response._content = b'{"status": 500, "code": 1, "message": "request error"}'
        return fake_response
```

**è¯·æ±‚æœºåˆ¶ç‰¹ç‚¹**ï¼š
- **æ™ºèƒ½åˆ‡æ¢**: åˆ†äº«é“¾æ¥è‡ªåŠ¨åˆ‡æ¢åˆ°ç§»åŠ¨ç«¯API
- **å®Œæ•´ä¼ªè£…**: ç§»åŠ¨ç«¯è¯·æ±‚å‚æ•°å®Œæ•´ä¼ªè£…
- **å®¹é”™å¤„ç†**: ç½‘ç»œå¼‚å¸¸æ—¶åˆ›å»ºå‡å“åº”
- **å‚æ•°æ³¨å…¥**: è‡ªåŠ¨æ³¨å…¥ç§»åŠ¨ç«¯å¿…è¦å‚æ•°

### 4. æ ¸å¿ƒAPIæ–¹æ³•

#### è´¦æˆ·ä¿¡æ¯è·å– (è¡Œ 428-444)

```python
def init(self):
    account_info = self.get_account_info()
    if account_info:
        self.is_active = True
        self.nickname = account_info["nickname"]
        return account_info
    else:
        return False

def get_account_info(self):
    url = "https://pan.quark.cn/account/info"
    querystring = {"fr": "pc", "platform": "pc"}
    response = self._send_request("GET", url, params=querystring).json()
    if response.get("data"):
        return response["data"]
    else:
        return False
```

#### è´¦å·éªŒè¯ (è¡Œ 1043-1056)

```python
def verify_account(account):
    # éªŒè¯è´¦å·
    print(f"â–¶ï¸ éªŒè¯ç¬¬{account.index}ä¸ªè´¦å·")
    if "__uid" not in account.cookie:
        print(f"ğŸ’¡ ä¸å­˜åœ¨cookieå¿…è¦å‚æ•°ï¼Œåˆ¤æ–­ä¸ºä»…ç­¾åˆ°")
        return False
    else:
        account_info = account.init()
        if not account_info:
            add_notify(f"ğŸ‘¤ ç¬¬{account.index}ä¸ªè´¦å·ç™»å½•å¤±è´¥ï¼Œcookieæ— æ•ˆâŒ")
            return False
        else:
            print(f"ğŸ‘¤ è´¦å·æ˜µç§°: {account_info['nickname']}âœ…")
            return True
```

#### æ¯æ—¥ç­¾åˆ°åŠŸèƒ½ (è¡Œ 446-487)

```python
def get_growth_info(self):
    url = f"{self.BASE_URL_APP}/1/clouddrive/capacity/growth/info"
    querystring = {
        "pr": "ucpro",
        "fr": "android",
        "kps": self.mparam.get("kps"),
        "sign": self.mparam.get("sign"),
        "vcode": self.mparam.get("vcode"),
    }
    response = self._send_request("GET", url, params=querystring).json()
    if response.get("data"):
        return response["data"]
    else:
        return False

def get_growth_sign(self):
    url = f"{self.BASE_URL_APP}/1/clouddrive/capacity/growth/sign"
    querystring = {
        "pr": "ucpro",
        "fr": "android",
        "kps": self.mparam.get("kps"),
        "sign": self.mparam.get("sign"),
        "vcode": self.mparam.get("vcode"),
    }
    payload = {
        "sign_cyclic": True,
    }
    response = self._send_request(
        "POST", url, json=payload, params=querystring
    ).json()
    if response.get("data"):
        return True, response["data"]["sign_daily_reward"]
    else:
        return False, response["message"]
```

#### æ–‡ä»¶å¤§å°æ ¼å¼åŒ– (è¡Œ 1059-1065)

```python
def format_bytes(size_bytes: int) -> str:
    units = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    i = 0
    while size_bytes >= 1024 and i < len(units) - 1:
        size_bytes /= 1024
        i += 1
    return f"{size_bytes:.2f} {units[i]}"
```

#### åˆ†äº«é“¾æ¥å¤„ç† (è¡Œ 489-533)

```python
def get_stoken(self, pwd_id, passcode=""):
    url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/token"
    querystring = {"pr": "ucpro", "fr": "pc"}
    payload = {"pwd_id": pwd_id, "passcode": passcode}
    response = self._send_request(
        "POST", url, json=payload, params=querystring
    ).json()
    return response

def get_detail(self, pwd_id, stoken, pdir_fid, _fetch_share=0, fetch_share_full_path=0):
    list_merge = []
    page = 1
    while True:
        url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/detail"
        querystring = {
            "pr": "ucpro", "fr": "pc",
            "pwd_id": pwd_id, "stoken": stoken, "pdir_fid": pdir_fid,
            "force": "0", "_page": page, "_size": "50",
            "_fetch_banner": "0", "_fetch_share": _fetch_share,
            "_fetch_total": "1", "_sort": "file_type:asc,updated_at:desc",
            "ver": "2", "fetch_share_full_path": fetch_share_full_path,
        }
        response = self._send_request("GET", url, params=querystring).json()
        if response["code"] != 0:
            return response
        if response["data"]["list"]:
            list_merge += response["data"]["list"]
            page += 1
        else:
            break
        if len(list_merge) >= response["metadata"]["_total"]:
            break
    response["data"]["list"] = list_merge
    return response
```

**åˆ†é¡µå¤„ç†ç‰¹ç‚¹**ï¼š
- **è‡ªåŠ¨ç¿»é¡µ**: å¤„ç†å¤§é‡æ–‡ä»¶çš„åˆ†é¡µè·å–
- **æ€§èƒ½ä¼˜åŒ–**: 50ä¸ªæ–‡ä»¶/é¡µçš„åˆç†åˆ†é¡µå¤§å°
- **å®Œæ•´æ€§ä¿è¯**: ç¡®ä¿è·å–æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯

#### æ–‡ä»¶æ“ä½œAPI (è¡Œ 535-702)

```python
def get_fids(self, file_paths):
    fids = []
    while True:
        url = f"{self.BASE_URL}/1/clouddrive/file/info/path_list"
        querystring = {"pr": "ucpro", "fr": "pc"}
        payload = {"file_path": file_paths[:50], "namespace": "0"}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        if response["code"] == 0:
            fids += response["data"]
            file_paths = file_paths[50:]
        else:
            print(f"è·å–ç›®å½•IDï¼šå¤±è´¥, {response['message']}")
            break
        if len(file_paths) == 0:
            break
    return fids

def ls_dir(self, pdir_fid, **kwargs):
    list_merge = []
    page = 1
    while True:
        url = f"{self.BASE_URL}/1/clouddrive/file/sort"
        querystring = {
            "pr": "ucpro", "fr": "pc", "uc_param_str": "",
            "pdir_fid": pdir_fid, "_page": page, "_size": "50",
            "_fetch_total": "1", "_fetch_sub_dirs": "0",
            "_sort": "file_type:asc,updated_at:desc",
            "_fetch_full_path": kwargs.get("fetch_full_path", 0),
        }
        response = self._send_request("GET", url, params=querystring).json()
        if response["code"] != 0:
            return response
        if response["data"]["list"]:
            list_merge += response["data"]["list"]
            page += 1
        else:
            break
        if len(list_merge) >= response["metadata"]["_total"]:
            break
    response["data"]["list"] = list_merge
    return response

def save_file(self, fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken):
    url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/save"
    querystring = {
        "pr": "ucpro", "fr": "pc", "uc_param_str": "",
        "app": "clouddrive", "__dt": int(random.uniform(1, 5) * 60 * 1000),
        "__t": datetime.now().timestamp(),
    }
    payload = {
        "fid_list": fid_list, "fid_token_list": fid_token_list,
        "to_pdir_fid": to_pdir_fid, "pwd_id": pwd_id, "stoken": stoken,
        "pdir_fid": "0", "scene": "link",
    }
    response = self._send_request("POST", url, json=payload, params=querystring)
    return response.json()

def query_task(self, task_id):
    retry_index = 0
    while True:
        url = f"{self.BASE_URL}/1/clouddrive/task"
        querystring = {
            "pr": "ucpro", "fr": "pc", "uc_param_str": "",
            "task_id": task_id, "retry_index": retry_index,
            "__dt": int(random.uniform(1, 5) * 60 * 1000),
            "__t": datetime.now().timestamp(),
        }
        response = self._send_request("GET", url, params=querystring).json()
        if response["data"]["status"] == 2:
            if retry_index > 0:
                print()
            break
        else:
            if retry_index == 0:
                print(f"æ­£åœ¨ç­‰å¾…[{response['data']['task_title']}]æ‰§è¡Œç»“æœ", end="", flush=True)
            else:
                print(".", end="", flush=True)
            retry_index += 1
            time.sleep(0.500)
    return response
```

#### æ–‡ä»¶ç®¡ç†æ“ä½œ (è¡Œ 639-702)

```python
def download(self, fids):
    url = f"{self.BASE_URL}/1/clouddrive/file/download"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {"fids": fids}
    response = self._send_request("POST", url, json=payload, params=querystring)
    set_cookie = response.cookies.get_dict()
    cookie_str = "; ".join([f"{key}={value}" for key, value in set_cookie.items()])
    return response.json(), cookie_str

def mkdir(self, dir_path):
    url = f"{self.BASE_URL}/1/clouddrive/file"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {
        "pdir_fid": "0", "file_name": "", "dir_path": dir_path,
        "dir_init_lock": False,
    }
    response = self._send_request("POST", url, json=payload, params=querystring).json()
    return response

def rename(self, fid, file_name):
    url = f"{self.BASE_URL}/1/clouddrive/file/rename"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {"fid": fid, "file_name": file_name}
    response = self._send_request("POST", url, json=payload, params=querystring).json()
    return response

def delete(self, filelist):
    url = f"{self.BASE_URL}/1/clouddrive/file/delete"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {"action_type": 2, "filelist": filelist, "exclude_fids": []}
    response = self._send_request("POST", url, json=payload, params=querystring).json()
    return response
```

#### å›æ”¶ç«™æ“ä½œ (è¡Œ 680-702)

```python
def recycle_list(self, page=1, size=30):
    url = f"{self.BASE_URL}/1/clouddrive/file/recycle/list"
    querystring = {
        "_page": page, "_size": size,
        "pr": "ucpro", "fr": "pc", "uc_param_str": "",
    }
    response = self._send_request("GET", url, params=querystring).json()
    return response["data"]["list"]

def recycle_remove(self, record_list):
    url = f"{self.BASE_URL}/1/clouddrive/file/recycle/remove"
    querystring = {"uc_param_str": "", "fr": "pc", "pr": "ucpro"}
    payload = {
        "select_mode": 2,
        "record_list": record_list,
    }
    response = self._send_request(
        "POST", url, json=payload, params=querystring
    ).json()
    return response
```

## ğŸ”„ ä»»åŠ¡æ‰§è¡Œæµç¨‹å’Œæ’ä»¶ç³»ç»Ÿ

### 1. ä¸»æ‰§è¡Œå‡½æ•° (è¡Œ 1176-1267)

```python
def main():
    global CONFIG_DATA
    start_time = datetime.now()
    print(f"===============ç¨‹åºå¼€å§‹===============")
    print(f"â° æ‰§è¡Œæ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # è¯»å–å¯åŠ¨å‚æ•°
    config_path = sys.argv[1] if len(sys.argv) > 1 else "quark_config.json"

    # æ¨é€æµ‹è¯•æ¨¡å¼
    if os.environ.get("QUARK_TEST", "").lower() == "true":
        print(f"===============é€šçŸ¥æµ‹è¯•===============")
        CONFIG_DATA["push_config"] = json.loads(os.environ.get("PUSH_CONFIG"))
        send_ql_notify("ã€å¤¸å…‹è‡ªåŠ¨è½¬å­˜ã€‘",
                      f"é€šçŸ¥æµ‹è¯•\n\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        if cookies := json.loads(os.environ.get("COOKIE", "[]")):
            print(f"===============è½¬å­˜æµ‹è¯•===============")
            accounts = Quark(cookies[0])
            accounts.do_save_check("https://pan.quark.cn/s/1ed94d530d63", "/æ¥è‡ªï¼šåˆ†äº«")
            print()
        return

    # ä»ç¯å¢ƒå˜é‡ä¸­è·å– TASKLIST
    tasklist_from_env = []
    if tasklist_json := os.environ.get("TASKLIST"):
        try:
            tasklist_from_env = json.loads(tasklist_json)
        except Exception as e:
            print(f"ä»ç¯å¢ƒå˜é‡è§£æä»»åŠ¡åˆ—è¡¨å¤±è´¥ {e}")

    # é…ç½®æ–‡ä»¶å¤„ç†
    if not os.path.exists(config_path):
        if os.environ.get("QUARK_COOKIE"):
            print(f"âš™ï¸ è¯»å–åˆ° QUARK_COOKIE ç¯å¢ƒå˜é‡ï¼Œä»…ç­¾åˆ°é¢†ç©ºé—´ã€‚å¦‚éœ€æ‰§è¡Œè½¬å­˜ï¼Œè¯·åˆ é™¤è¯¥ç¯å¢ƒå˜é‡åé…ç½® {config_path} æ–‡ä»¶")
            cookie_val = os.environ.get("QUARK_COOKIE")
            cookie_form_file = False
        else:
            print(f"âš™ï¸ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨âŒï¼Œæ­£è¿œç¨‹ä»ä¸‹è½½é…ç½®æ¨¡ç‰ˆ")
            config_url = f"{GH_PROXY}https://raw.githubusercontent.com/Cp0204/quark_auto_save/main/quark_config.json"
            if Config.download_file(config_url, config_path):
                print("âš™ï¸ é…ç½®æ¨¡ç‰ˆä¸‹è½½æˆåŠŸâœ…ï¼Œè¯·åˆ°ç¨‹åºç›®å½•ä¸­æ‰‹åŠ¨é…ç½®")
            return
    else:
        print(f"âš™ï¸ æ­£ä» {config_path} æ–‡ä»¶ä¸­è¯»å–é…ç½®")
        CONFIG_DATA = Config.read_json(config_path)
        Config.breaking_change_update(CONFIG_DATA)
        cookie_val = CONFIG_DATA.get("cookie")
        cookie_form_file = True

    # è·å–cookieå¹¶åˆå§‹åŒ–è´¦å·
    cookies = Config.get_cookies(cookie_val)
    if not cookies:
        print("âŒ cookie æœªé…ç½®")
        return
    accounts = [Quark(cookie, index) for index, cookie in enumerate(cookies)]

    # ç­¾åˆ°ä»»åŠ¡
    print(f"===============ç­¾åˆ°ä»»åŠ¡===============")
    if tasklist_from_env:
        verify_account(accounts[0])
    else:
        for account in accounts:
            verify_account(account)
            do_sign(account)
    print()

    # è½¬å­˜ä»»åŠ¡
    if accounts[0].is_active and cookie_form_file:
        print(f"===============è½¬å­˜ä»»åŠ¡===============")
        if tasklist_from_env:
            do_save(accounts[0], tasklist_from_env)
        else:
            do_save(accounts[0], CONFIG_DATA.get("tasklist", []))
        print()

    # é€šçŸ¥æ¨é€
    if NOTIFYS:
        notify_body = "\n".join(NOTIFYS)
        print(f"===============æ¨é€é€šçŸ¥===============")
        send_ql_notify("ã€å¤¸å…‹è‡ªåŠ¨è½¬å­˜ã€‘", notify_body)
        print()

    if cookie_form_file:
        Config.write_json(config_path, CONFIG_DATA)

    print(f"===============ç¨‹åºç»“æŸ===============")
    duration = datetime.now() - start_time
    print(f"ğŸ˜ƒ è¿è¡Œæ—¶é•¿: {round(duration.total_seconds(), 2)}s")
    print()
```

**æ‰§è¡Œæµç¨‹ç‰¹ç‚¹**ï¼š
- **å¤šæ¨¡å¼æ”¯æŒ**: æµ‹è¯•æ¨¡å¼ã€ç¯å¢ƒå˜é‡æ¨¡å¼ã€é…ç½®æ–‡ä»¶æ¨¡å¼
- **è‡ªåŠ¨é…ç½®**: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶è‡ªåŠ¨ä¸‹è½½æ¨¡æ¿
- **åˆ†é˜¶æ®µæ‰§è¡Œ**: ç­¾åˆ°ã€è½¬å­˜ã€é€šçŸ¥åˆ†é˜¶æ®µå¤„ç†
- **é”™è¯¯å¤„ç†**: å®Œæ•´çš„å¼‚å¸¸å¤„ç†å’Œç”¨æˆ·æç¤º

### 2. ç­¾åˆ°åŠŸèƒ½ (è¡Œ 1068-1100)

```python
def do_sign(account):
    if not account.mparam:
        print("â­ï¸ ç§»åŠ¨ç«¯å‚æ•°æœªè®¾ç½®ï¼Œè·³è¿‡ç­¾åˆ°")
        print()
        return

    # æ¯æ—¥é¢†ç©ºé—´
    growth_info = account.get_growth_info()
    if growth_info:
        growth_message = f"ğŸ’¾ {'88VIP' if growth_info['88VIP'] else 'æ™®é€šç”¨æˆ·'} æ€»ç©ºé—´ï¼š{format_bytes(growth_info['total_capacity'])}ï¼Œç­¾åˆ°ç´¯è®¡è·å¾—ï¼š{format_bytes(growth_info['cap_composition'].get('sign_reward', 0))}"
        if growth_info["cap_sign"]["sign_daily"]:
            sign_message = f"ğŸ“… ç­¾åˆ°è®°å½•: ä»Šæ—¥å·²ç­¾åˆ°+{int(growth_info['cap_sign']['sign_daily_reward']/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']}/{growth_info['cap_sign']['sign_target']})âœ…"
            message = f"{sign_message}\n{growth_message}"
            print(message)
        else:
            sign, sign_return = account.get_growth_sign()
            if sign:
                sign_message = f"ğŸ“… æ‰§è¡Œç­¾åˆ°: ä»Šæ—¥ç­¾åˆ°+{int(sign_return/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']+1}/{growth_info['cap_sign']['sign_target']})âœ…"
                message = f"{sign_message}\n{growth_message}"
                if (
                    str(CONFIG_DATA.get("push_config", {}).get("QUARK_SIGN_NOTIFY")).lower()
                    == "false"
                    or os.environ.get("QUARK_SIGN_NOTIFY") == "false"
                ):
                    print(message)
                else:
                    message = message.replace("ä»Šæ—¥", f"[{account.nickname}]ä»Šæ—¥")
                    add_notify(message)
            else:
                print(f"ğŸ“… ç­¾åˆ°å¼‚å¸¸: {sign_return}")
    print()
```

### 3. ä»»åŠ¡æ‰§è¡Œæ ¸å¿ƒé€»è¾‘ (è¡Œ 1102-1174)

```python
def do_save(account, tasklist=[]):
    print(f"ğŸ§© è½½å…¥æ’ä»¶")
    plugins, CONFIG_DATA["plugins"], task_plugins_config = Config.load_plugins(
        CONFIG_DATA.get("plugins", {})
    )
    print(f"è½¬å­˜è´¦å·: {account.nickname}")

    # è·å–å…¨éƒ¨ä¿å­˜ç›®å½•fid
    account.update_savepath_fid(tasklist)

    def is_time(task):
        return (
            not task.get("enddate")
            or (
                datetime.now().date()
                <= datetime.strptime(task["enddate"], "%Y-%m-%d").date()
            )
        ) and (
            "runweek" not in task
            or (datetime.today().weekday() + 1 in task.get("runweek"))
        )

    # æ‰§è¡Œä»»åŠ¡
    for index, task in enumerate(tasklist):
        print()
        print(f"#{index+1}------------------")
        print(f"ä»»åŠ¡åç§°: {task['taskname']}")
        print(f"åˆ†äº«é“¾æ¥: {task['shareurl']}")
        print(f"ä¿å­˜è·¯å¾„: {task['savepath']}")
        if task.get("pattern"):
            print(f"æ­£åˆ™åŒ¹é…: {task['pattern']}")
        if task.get("replace"):
            print(f"æ­£åˆ™æ›¿æ¢: {task['replace']}")
        if task.get("update_subdir"):
            print(f"æ›´å­ç›®å½•: {task['update_subdir']}")
        if task.get("runweek") or task.get("enddate"):
            print(f"è¿è¡Œå‘¨æœŸ: WK{task.get('runweek',[])} ~ {task.get('enddate','forever')}")
        print()

        # åˆ¤æ–­ä»»åŠ¡å‘¨æœŸ
        if not is_time(task):
            print(f"ä»»åŠ¡ä¸åœ¨è¿è¡Œå‘¨æœŸå†…ï¼Œè·³è¿‡")
        else:
            is_new_tree = account.do_save_task(task)

            # è¡¥å……ä»»åŠ¡çš„æ’ä»¶é…ç½®
            def merge_dicts(a, b):
                result = a.copy()
                for key, value in b.items():
                    if (
                        key in result
                        and isinstance(result[key], dict)
                        and isinstance(value, dict)
                    ):
                        result[key] = merge_dicts(result[key], value)
                    elif key not in result:
                        result[key] = value
                return result

            task["addition"] = merge_dicts(
                task.get("addition", {}), task_plugins_config
            )

            # è°ƒç”¨æ’ä»¶
            if is_new_tree:
                print(f"ğŸ§© è°ƒç”¨æ’ä»¶")
                for plugin_name, plugin in plugins.items():
                    if plugin.is_active:
                        task = (
                            plugin.run(task, account=account, tree=is_new_tree) or task
                        )
    print()
```

### 4. å•ä¸ªä»»åŠ¡å¤„ç† (è¡Œ 797-828)

```python
def do_save_task(self, task):
    # åˆ¤æ–­èµ„æºå¤±æ•ˆè®°å½•
    if task.get("shareurl_ban"):
        print(f"ã€Š{task['taskname']}ã€‹ï¼š{task['shareurl_ban']}")
        return

    # é“¾æ¥è½¬æ¢æ‰€éœ€å‚æ•°
    pwd_id, passcode, pdir_fid, _ = self.extract_url(task["shareurl"])

    # è·å–stokenï¼ŒåŒæ—¶å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
    get_stoken = self.get_stoken(pwd_id, passcode)
    if get_stoken.get("status") == 200:
        stoken = get_stoken["data"]["stoken"]
    elif get_stoken.get("status") == 500:
        print(f"è·³è¿‡ä»»åŠ¡ï¼šç½‘ç»œå¼‚å¸¸ {get_stoken.get('message')}")
        return
    else:
        message = get_stoken.get("message")
        add_notify(f"âŒã€Š{task['taskname']}ã€‹ï¼š{message}\n")
        task["shareurl_ban"] = message
        return

    updated_tree = self.dir_check_and_save(task, pwd_id, stoken, pdir_fid)
    if updated_tree.size(1) > 0:
        self.do_rename(updated_tree)
        print()
        add_notify(f"âœ…ã€Š{task['taskname']}ã€‹æ·»åŠ è¿½æ›´ï¼š\n{updated_tree}")
        return updated_tree
    else:
        print(f"ä»»åŠ¡ç»“æŸï¼šæ²¡æœ‰æ–°çš„è½¬å­˜ä»»åŠ¡")
        return False
```

### 5. ç›®å½•æ£€æŸ¥å’Œä¿å­˜æ ¸å¿ƒç®—æ³• (è¡Œ 830-1013)

```python
def dir_check_and_save(self, task, pwd_id, stoken, pdir_fid="", subdir_path=""):
    tree = Tree()
    # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
    share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["data"]["list"]

    if not share_file_list:
        if subdir_path == "":
            task["shareurl_ban"] = "åˆ†äº«ä¸ºç©ºï¼Œæ–‡ä»¶å·²è¢«åˆ†äº«è€…åˆ é™¤"
            add_notify(f"âŒã€Š{task['taskname']}ã€‹ï¼š{task['shareurl_ban']}\n")
        return tree
    elif (
        len(share_file_list) == 1
        and share_file_list[0]["dir"]
        and subdir_path == ""
    ):  # ä»…æœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹
        print("ğŸ§  è¯¥åˆ†äº«æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œè¯»å–æ–‡ä»¶å¤¹å†…åˆ—è¡¨")
        share_file_list = self.get_detail(
            pwd_id, stoken, share_file_list[0]["fid"]
        )["data"]["list"]

    # è·å–ç›®æ ‡ç›®å½•æ–‡ä»¶åˆ—è¡¨
    savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
    if not self.savepath_fid.get(savepath):
        if get_fids := self.get_fids([savepath]):
            self.savepath_fid[savepath] = get_fids[0]["fid"]
        else:
            print(f"âŒ ç›®å½• {savepath} fidè·å–å¤±è´¥ï¼Œè·³è¿‡è½¬å­˜")
            return tree
    to_pdir_fid = self.savepath_fid[savepath]
    dir_file_list = self.ls_dir(to_pdir_fid)["data"]["list"]
    dir_filename_list = [dir_file["file_name"] for dir_file in dir_file_list]

    # æ–‡ä»¶å‘½åç±»
    mr = MagicRename(CONFIG_DATA.get("magic_regex", {}))
    mr.set_taskname(task["taskname"])

    # é­”æ³•æ­£åˆ™è½¬æ¢
    pattern, replace = mr.magic_regex_conv(
        task.get("pattern", ""), task.get("replace", "")
    )

    # éœ€ä¿å­˜çš„æ–‡ä»¶æ¸…å•
    need_save_list = []

    # æ·»åŠ ç¬¦åˆçš„
    for share_file in share_file_list:
        search_pattern = (
            task["update_subdir"]
            if share_file["dir"] and task.get("update_subdir")
            else pattern
        )
        # æ­£åˆ™æ–‡ä»¶ååŒ¹é…
        if re.search(search_pattern, share_file["file_name"]):
            # åˆ¤æ–­åŸæ–‡ä»¶åæ˜¯å¦å­˜åœ¨ï¼Œå¤„ç†å¿½ç•¥æ‰©å±•å
            if not mr.is_exists(
                share_file["file_name"],
                dir_filename_list,
                (task.get("ignore_extension") and not share_file["dir"]),
            ):
                # æ–‡ä»¶å¤¹ã€å­ç›®å½•æ–‡ä»¶ä¸è¿›è¡Œé‡å‘½å
                if share_file["dir"] or subdir_path:
                    share_file["file_name_re"] = share_file["file_name"]
                    need_save_list.append(share_file)
                else:
                    # æ›¿æ¢åçš„æ–‡ä»¶å
                    file_name_re = mr.sub(pattern, replace, share_file["file_name"])
                    # åˆ¤æ–­æ›¿æ¢åçš„æ–‡ä»¶åæ˜¯å¦å­˜åœ¨
                    if not mr.is_exists(
                        file_name_re,
                        dir_filename_list,
                        task.get("ignore_extension"),
                    ):
                        share_file["file_name_re"] = file_name_re
                        need_save_list.append(share_file)
            elif share_file["dir"]:
                # å­˜åœ¨å¹¶æ˜¯ä¸€ä¸ªç›®å½•ï¼Œå†éå­ç›®å½•
                if task.get("update_subdir", False) and re.search(
                    task["update_subdir"], share_file["file_name"]
                ):
                    if task.get("update_subdir_resave_mode", False):
                        # é‡å­˜æ¨¡å¼ï¼šåˆ é™¤è¯¥ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶ï¼Œé‡æ–°è½¬å­˜
                        print(f"é‡å­˜å­ç›®å½•ï¼š{savepath}/{share_file['file_name']}")
                        # åˆ é™¤å­ç›®å½•ã€å›æ”¶ç«™ä¸­å½»åº•åˆ é™¤
                        subdir = next(
                            (
                                f
                                for f in dir_file_list
                                if f["file_name"] == share_file["file_name"]
                            ),
                            None,
                        )
                        delete_return = self.delete([subdir["fid"]])
                        self.query_task(delete_return["data"]["task_id"])
                        recycle_list = self.recycle_list()
                        record_id_list = [
                            item["record_id"]
                            for item in recycle_list
                            if item["fid"] == subdir["fid"]
                        ]
                        self.recycle_remove(record_id_list)
                        # ä½œä¸ºæ–°æ–‡ä»¶æ·»åŠ åˆ°è½¬å­˜åˆ—è¡¨
                        share_file["file_name_re"] = share_file["file_name"]
                        need_save_list.append(share_file)
                    else:
                        # é€’å½’æ¨¡å¼
                        print(f"æ£€æŸ¥å­ç›®å½•ï¼š{savepath}/{share_file['file_name']}")
                        subdir_tree = self.dir_check_and_save(
                            task,
                            pwd_id,
                            stoken,
                            share_file["fid"],
                            f"{subdir_path}/{share_file['file_name']}",
                        )
                        if subdir_tree.size(1) > 0:
                            # åˆå¹¶å­ç›®å½•æ ‘
                            tree.create_node(
                                "ğŸ“" + share_file["file_name"],
                                share_file["fid"],
                                parent=pdir_fid,
                                data={
                                    "is_dir": share_file["dir"],
                                },
                            )
                            tree.merge(share_file["fid"], subdir_tree, deep=False)
            # æŒ‡å®šæ–‡ä»¶å¼€å§‹è®¢é˜…/åˆ°è¾¾æŒ‡å®šæ–‡ä»¶ï¼ˆå«ï¼‰ç»“æŸå†é
            if share_file["fid"] == task.get("startfid", ""):
                break

    if re.search(r"\{I+\}", replace):
        mr.set_dir_file_list(dir_file_list, replace)
        mr.sort_file_list(need_save_list)

    # è½¬å­˜æ–‡ä»¶
    fid_list = [item["fid"] for item in need_save_list]
    fid_token_list = [item["share_fid_token"] for item in need_save_list]
    if fid_list:
        err_msg = None
        save_as_top_fids = []
        while fid_list:
            # åˆ†æ¬¡è½¬å­˜ï¼Œ100ä¸ª/æ¬¡ï¼Œå› query_taskè¿”å›save_as_top_fidsæœ€å¤š100
            save_file_return = self.save_file(
                fid_list[:100], fid_token_list[:100], to_pdir_fid, pwd_id, stoken
            )
            fid_list = fid_list[100:]
            fid_token_list = fid_token_list[100:]
            if save_file_return["code"] == 0:
                # è½¬å­˜æˆåŠŸï¼ŒæŸ¥è¯¢è½¬å­˜ç»“æœ
                task_id = save_file_return["data"]["task_id"]
                query_task_return = self.query_task(task_id)
                if query_task_return["code"] == 0:
                    save_as_top_fids.extend(
                        query_task_return["data"]["save_as"]["save_as_top_fids"]
                    )
                else:
                    err_msg = query_task_return["message"]
            else:
                err_msg = save_file_return["message"]
            if err_msg:
                add_notify(f"âŒã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥ï¼š{err_msg}\n")

    # å»ºç«‹ç›®å½•æ ‘
    for index, item in enumerate(need_save_list):
        icon = self._get_file_icon(item)
        tree.create_node(
            f"{icon}{item['file_name_re']}",
            item["fid"],
            parent=pdir_fid,
            data={
                "file_name": item["file_name"],
                "file_name_re": item["file_name_re"],
                "fid": f"{save_as_top_fids[index]}",
                "path": f"{savepath}/{item['file_name_re']}",
                "is_dir": item["dir"],
                "obj_category": item.get("obj_category", ""),
            },
        )
    return tree
```

**æ ¸å¿ƒç®—æ³•ç‰¹ç‚¹**ï¼š
- **æ™ºèƒ½å•æ–‡ä»¶å¤¹æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹å•æ–‡ä»¶å¤¹åˆ†äº«
- **å¢é‡æ›´æ–°**: ä»…è½¬å­˜æ–°æ–‡ä»¶ï¼Œé¿å…é‡å¤
- **é€’å½’ç›®å½•å¤„ç†**: æ”¯æŒå­ç›®å½•é€’å½’æ›´æ–°
- **æ‰¹é‡è½¬å­˜**: 100ä¸ªæ–‡ä»¶/æ‰¹æ¬¡çš„æ€§èƒ½ä¼˜åŒ–
- **æ ‘å½¢ç»“æ„**: ä½¿ç”¨treelibæ„å»ºæ–‡ä»¶æ ‘ç»“æ„

### 6. URLè§£æå·¥å…· (è¡Œ 707-723)

```python
def extract_url(self, url):
    # pwd_id
    match_id = re.search(r"/s/(\w+)", url)
    pwd_id = match_id.group(1) if match_id else None
    # passcode
    match_pwd = re.search(r"pwd=(\w+)", url)
    passcode = match_pwd.group(1) if match_pwd else ""
    # path: fid-name
    # Legacy 20250905
    paths = []
    matches = re.findall(r"/(\w{32})-?([^/]+)?", url)
    for match in matches:
        fid = match[0]
        name = urllib.parse.unquote(match[1]).replace("*101", "-")
        paths.append({"fid": fid, "name": name})
    pdir_fid = paths[-1]["fid"] if matches else 0
    return pwd_id, passcode, pdir_fid, paths
```

### 7. ç›®å½•è·¯å¾„æ›´æ–° (è¡Œ 725-754)

```python
def update_savepath_fid(self, tasklist):
    dir_paths = [
        re.sub(r"/{2,}", "/", f"/{item['savepath']}")
        for item in tasklist
        if not item.get("enddate")
        or (
            datetime.now().date()
            <= datetime.strptime(item["enddate"], "%Y-%m-%d").date()
        )
    ]
    if not dir_paths:
        return False
    dir_paths_exist_arr = self.get_fids(dir_paths)
    dir_paths_exist = [item["file_path"] for item in dir_paths_exist_arr]
    # æ¯”è¾ƒåˆ›å»ºä¸å­˜åœ¨çš„
    dir_paths_unexist = list(set(dir_paths) - set(dir_paths_exist) - set(["/"]))
    for dir_path in dir_paths_unexist:
        mkdir_return = self.mkdir(dir_path)
        if mkdir_return["code"] == 0:
            new_dir = mkdir_return["data"]
            dir_paths_exist_arr.append(
                {"file_path": dir_path, "fid": new_dir["fid"]}
            )
            print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{dir_path}")
        else:
            print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{dir_path} å¤±è´¥, {mkdir_return['message']}")
    # å‚¨å­˜ç›®æ ‡ç›®å½•çš„fid
    for dir_path in dir_paths_exist_arr:
        self.savepath_fid[dir_path["file_path"]] = dir_path["fid"]
```

### 8. æ–‡ä»¶é‡å‘½åå¤„ç† (è¡Œ 1015-1040)

```python
def do_rename(self, tree, node_id=None):
    if node_id is None:
        node_id = tree.root
    for child in tree.children(node_id):
        file = child.data
        if file.get("is_dir"):
            # self.do_rename(tree, child.identifier)
            pass
        elif file.get("file_name_re") and file["file_name_re"] != file["file_name"]:
            rename_ret = self.rename(file["fid"], file["file_name_re"])
            print(f"é‡å‘½åï¼š{file['file_name']} â†’ {file['file_name_re']}")
            if rename_ret["code"] != 0:
                print(f"      â†‘ å¤±è´¥ï¼Œ{rename_ret['message']}")

def _get_file_icon(self, f):
    if f.get("dir"):
        return "ğŸ“"
    ico_maps = {
        "video": "ğŸï¸",
        "image": "ğŸ–¼ï¸",
        "audio": "ğŸµ",
        "doc": "ğŸ“„",
        "archive": "ğŸ“¦",
        "default": "",
    }
    return ico_maps.get(f.get("obj_category"), "")
```

### 9. æµ‹è¯•å’ŒéªŒè¯åŠŸèƒ½ (è¡Œ 756-795)

```python
def do_save_check(self, shareurl, savepath):
    try:
        pwd_id, passcode, pdir_fid, _ = self.extract_url(shareurl)
        stoken = self.get_stoken(pwd_id, passcode)["data"]["stoken"]
        share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["data"]["list"]
        print(f"è·å–åˆ†äº«: {share_file_list}")
        fid_list = [item["fid"] for item in share_file_list]
        fid_token_list = [item["share_fid_token"] for item in share_file_list]
        get_fids = self.get_fids([savepath])
        to_pdir_fid = (
            get_fids[0]["fid"] if get_fids else self.mkdir(savepath)["data"]["fid"]
        )
        save_file = self.save_file(
            fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken
        )
        print(f"è½¬å­˜æ–‡ä»¶: {save_file}")
        if save_file["code"] == 0:
            task_id = save_file["data"]["task_id"]
            query_task = self.query_task(task_id)
            print(f"æŸ¥è¯¢è½¬å­˜: {query_task}")
            if query_task["code"] == 0:
                del_list = query_task["data"]["save_as"]["save_as_top_fids"]
                if del_list:
                    delete_return = self.delete(del_list)
                    print(f"åˆ é™¤è½¬å­˜: {delete_return}")
                    recycle_list = self.recycle_list()
                    record_id_list = [
                        item["record_id"]
                        for item in recycle_list
                        if item["fid"] in del_list
                    ]
                    recycle_remove = self.recycle_remove(record_id_list)
                    print(f"æ¸…ç†è½¬å­˜: {recycle_remove}")
                    print(f"âœ… è½¬å­˜æµ‹è¯•æˆåŠŸ")
                    return True
        print(f"âŒ è½¬å­˜æµ‹è¯•å¤±è´¥: ä¸­æ–­")
        return False
    except Exception as e:
        print(f"âŒ è½¬å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
```

## ğŸ“Š æ¶æ„è®¾è®¡æ€»ç»“

### ğŸ—ï¸ æ•´ä½“æ¶æ„æ¨¡å¼

```mermaid
graph TB
    A[mainå‡½æ•°] --> B[é…ç½®åˆå§‹åŒ–]
    B --> C[è´¦å·éªŒè¯]
    C --> D[ç­¾åˆ°ä»»åŠ¡]
    D --> E[æ’ä»¶åŠ è½½]
    E --> F[è½¬å­˜ä»»åŠ¡]
    F --> G[é€šçŸ¥æ¨é€]

    F --> H[ä»»åŠ¡å¤„ç†å¾ªç¯]
    H --> I[é“¾æ¥éªŒè¯]
    I --> J[æ–‡ä»¶å¯¹æ¯”]
    J --> K[æ‰¹é‡è½¬å­˜]
    K --> L[é‡å‘½åå¤„ç†]

    E --> M[æ’ä»¶ç³»ç»Ÿ]
    M --> N[åŠ¨æ€åŠ è½½]
    M --> O[é…ç½®æ³¨å…¥]
    M --> P[ä»»åŠ¡æ‰§è¡Œ]
```

### ğŸ’¡ è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µ

#### 1. **ç­–ç•¥æ¨¡å¼** - MagicRename
```python
# ä¸åŒå‘½åç­–ç•¥çš„ç»Ÿä¸€æ¥å£
magic_regex = {
    "$TV": {"pattern": "...", "replace": "..."},
    "$BLACK_WORD": {"pattern": "...", "replace": "..."}
}
```

#### 2. **æ¨¡æ¿æ–¹æ³•æ¨¡å¼** - ä»»åŠ¡æ‰§è¡Œæµç¨‹
```python
def do_save_task(self, task):
    # 1. éªŒè¯é“¾æ¥
    # 2. è·å–æ–‡ä»¶åˆ—è¡¨
    # 3. å¯¹æ¯”æ£€æŸ¥
    # 4. æ‰§è¡Œè½¬å­˜
    # 5. é‡å‘½åå¤„ç†
```

#### 3. **å·¥å‚æ¨¡å¼** - æ’ä»¶ç³»ç»Ÿ
```python
module = importlib.import_module(f"{plugins_dir}.{module_name}")
ServerClass = getattr(module, module_name.capitalize())
plugin = ServerClass(**plugins_config[module_name])
```

#### 4. **å•ä¾‹æ¨¡å¼** - å…¨å±€é…ç½®
```python
global CONFIG_DATA
CONFIG_DATA = Config.read_json(config_path)
```

### ğŸ”§ æŠ€æœ¯äº®ç‚¹

1. **åŒç«¯APIé€‚é…**: è‡ªåŠ¨åˆ‡æ¢PCç«¯å’Œç§»åŠ¨ç«¯API
2. **æ™ºèƒ½é‡å‘½å**: é­”æ³•å˜é‡ç³»ç»Ÿæ”¯æŒå¤æ‚æ–‡ä»¶å‘½å
3. **å¢é‡åŒæ­¥**: ä»…è½¬å­˜æ–°æ–‡ä»¶ï¼Œé¿å…é‡å¤æ“ä½œ
4. **æ’ä»¶æ¶æ„**: é«˜åº¦å¯æ‰©å±•çš„æ’ä»¶ç³»ç»Ÿ
5. **æ‰¹é‡å¤„ç†**: ä¼˜åŒ–å¤§æ–‡ä»¶é›†çš„è½¬å­˜æ€§èƒ½
6. **å®¹é”™æœºåˆ¶**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

### ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

1. **ç›®å½•ç¼“å­˜**: `savepath_fid` ç¼“å­˜ç›®å½•IDæ˜ å°„
2. **æ‰¹é‡APIè°ƒç”¨**: 100ä¸ªæ–‡ä»¶/æ‰¹æ¬¡å‡å°‘è¯·æ±‚æ¬¡æ•°
3. **åˆ†é¡µå¤„ç†**: å¤„ç†å¤§é‡æ–‡ä»¶çš„åˆ†é¡µæœºåˆ¶
4. **è¿æ¥å¤ç”¨**: requestsä¼šè¯å¤ç”¨
5. **å†…å­˜ä¼˜åŒ–**: æµå¼å¤„ç†é¿å…å†…å­˜æº¢å‡º

### ğŸ›¡ï¸ å®‰å…¨è€ƒè™‘

1. **Cookieä¿æŠ¤**: æ•æ„Ÿä¿¡æ¯ä¸åœ¨æ—¥å¿—ä¸­æš´éœ²
2. **å‚æ•°éªŒè¯**: è¾“å…¥å‚æ•°çš„å®Œæ•´æ€§æ£€æŸ¥
3. **å¼‚å¸¸å¤„ç†**: ç½‘ç»œå¼‚å¸¸çš„ä¼˜é›…é™çº§
4. **èµ„æºæ¸…ç†**: è¿›ç¨‹å’Œæ–‡ä»¶çš„åŠæ—¶æ¸…ç†
5. **æƒé™æ§åˆ¶**: æœ€å°æƒé™åŸåˆ™

### ğŸ” æ ¸å¿ƒç®—æ³•åˆ†æ

#### æ–‡ä»¶åŒ¹é…ç®—æ³•
```python
# å¤šé‡åŒ¹é…ç­–ç•¥
if re.search(search_pattern, share_file["file_name"]):
    if not mr.is_exists(share_file["file_name"], dir_filename_list, ignore_ext):
        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦è½¬å­˜
```

#### ç›®å½•åŒæ­¥ç®—æ³•
```python
# é€’å½’ç›®å½•å¤„ç†
if share_file["dir"] and task.get("update_subdir"):
    subdir_tree = self.dir_check_and_save(task, pwd_id, stoken, share_file["fid"])
    tree.merge(share_file["fid"], subdir_tree, deep=False)
```

### ğŸ“ ä»£ç è´¨é‡è¯„ä¼°

### âœ… ä¼˜ç‚¹
1. **æ¶æ„æ¸…æ™°**: æ¨¡å—åŒ–è®¾è®¡ï¼ŒèŒè´£æ˜ç¡®
2. **æ‰©å±•æ€§å¼º**: æ’ä»¶ç³»ç»Ÿæ”¯æŒåŠŸèƒ½æ‰©å±•
3. **ç”¨æˆ·å‹å¥½**: è¯¦ç»†çš„æ—¥å¿—è¾“å‡ºå’Œé”™è¯¯æç¤º
4. **æ€§èƒ½ä¼˜åŒ–**: å¤šç§æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
5. **å®¹é”™ç¨³å®š**: å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶

### âš ï¸ æ”¹è¿›å»ºè®®
1. **ç±»å‹æ³¨è§£**: æ·»åŠ ç±»å‹æç¤ºæé«˜ä»£ç å¯è¯»æ€§
2. **å•å…ƒæµ‹è¯•**: å¢åŠ æµ‹è¯•ç”¨ä¾‹ç¡®ä¿ä»£ç è´¨é‡
3. **é…ç½®éªŒè¯**: æ·»åŠ é…ç½®é¡¹æ ¼å¼å’Œæœ‰æ•ˆæ€§éªŒè¯
4. **ç›‘æ§æŒ‡æ ‡**: æ·»åŠ æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡
5. **æ–‡æ¡£å®Œå–„**: æ›´è¯¦ç»†çš„APIæ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹

## ğŸ”Œ æ’ä»¶ç³»ç»Ÿæ·±åº¦è§£æ

### æ’ä»¶æ¥å£è§„èŒƒ
```python
class PluginTemplate:
    def __init__(self, **config):
        self.default_config = {...}
        self.config = {...}
        self.is_active = False

    def run(self, task, account=None, tree=None):
        # æ’ä»¶ä¸šåŠ¡é€»è¾‘
        return task
```

### æ’ä»¶ç”Ÿå‘½å‘¨æœŸ
1. **åŠ è½½é˜¶æ®µ**: åŠ¨æ€å¯¼å…¥å’Œå®ä¾‹åŒ–
2. **é…ç½®é˜¶æ®µ**: æ³¨å…¥é…ç½®å‚æ•°
3. **æ‰§è¡Œé˜¶æ®µ**: ä»»åŠ¡å®Œæˆåè§¦å‘
4. **æ¸…ç†é˜¶æ®µ**: èµ„æºé‡Šæ”¾å’Œæ¸…ç†

## ğŸ¯ ä½¿ç”¨åœºæ™¯å’Œæ‰©å±•æ€§

### å…¸å‹ä½¿ç”¨åœºæ™¯
1. **å‰§é›†è¿½æ›´**: è‡ªåŠ¨ç›‘æ§å‰§é›†æ›´æ–°å¹¶è½¬å­˜
2. **æ–‡ä»¶æ•´ç†**: æ™ºèƒ½é‡å‘½åå’Œåˆ†ç±»æ•´ç†
3. **æ‰¹é‡æ“ä½œ**: å¤§é‡æ–‡ä»¶çš„é«˜æ•ˆå¤„ç†
4. **å®šæ—¶ä»»åŠ¡**: å®šæœŸæ‰§è¡Œè½¬å­˜ä»»åŠ¡

### æ‰©å±•æ–¹å‘
1. **å¤šå¹³å°æ”¯æŒ**: æ‰©å±•åˆ°å…¶ä»–äº‘ç›˜å¹³å°
2. **AIé›†æˆ**: æ™ºèƒ½æ–‡ä»¶åˆ†ç±»å’Œå‘½å
3. **Webç•Œé¢**: å¯è§†åŒ–é…ç½®å’Œç®¡ç†
4. **åˆ†å¸ƒå¼**: å¤šèŠ‚ç‚¹ååŒå¤„ç†

è¿™ä¸ª `quark_auto_save.py` æ–‡ä»¶å±•ç°äº†ä¸€ä¸ªåŠŸèƒ½å®Œæ•´ã€æ¶æ„æ¸…æ™°çš„ç½‘ç»œçˆ¬è™«å’Œæ–‡ä»¶ç®¡ç†ç³»ç»Ÿçš„å®ç°ï¼Œé›†æˆäº†ç°ä»£åŒ–çš„è½¯ä»¶è®¾è®¡ç†å¿µå’Œæœ€ä½³å®è·µï¼Œæ˜¯ä¼˜ç§€çš„ä¼ä¸šçº§Pythonåº”ç”¨ç¤ºä¾‹ã€‚

---

*æ–‡æ¡£ç”Ÿæˆæ—¶é—´: 2025-11-20*
*åˆ†ææ–‡ä»¶ç‰ˆæœ¬: quark_auto_save.py (1268è¡Œ)*
*é¡¹ç›®åœ°å€: https://github.com/Cp0204/quark_auto_save*